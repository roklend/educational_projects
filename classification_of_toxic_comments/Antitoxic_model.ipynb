{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05f5f5aa",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Загрузка-и-подготовка-данных\" data-toc-modified-id=\"Загрузка-и-подготовка-данных-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Загрузка и подготовка данных</a></span><ul class=\"toc-item\"><li><span><a href=\"#Embedding-с-помощью-toxicBERT\" data-toc-modified-id=\"Embedding-с-помощью-toxicBERT-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Embedding с помощью toxicBERT</a></span></li><li><span><a href=\"#TF-IDF-признаки\" data-toc-modified-id=\"TF-IDF-признаки-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span><em>TF-IDF</em> признаки</a></span></li><li><span><a href=\"#Борьба-с-несбалансированностью-классов\" data-toc-modified-id=\"Борьба-с-несбалансированностью-классов-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Борьба с несбалансированностью классов</a></span></li></ul></li><li><span><a href=\"#Обучение-моделей\" data-toc-modified-id=\"Обучение-моделей-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение моделей</a></span><ul class=\"toc-item\"><li><span><a href=\"#Обучение-да-признаках-BERT\" data-toc-modified-id=\"Обучение-да-признаках-BERT-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Обучение да признаках BERT</a></span><ul class=\"toc-item\"><li><span><a href=\"#LightGBM\" data-toc-modified-id=\"LightGBM-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>LightGBM</a></span></li><li><span><a href=\"#RandomForestClassifier\" data-toc-modified-id=\"RandomForestClassifier-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>RandomForestClassifier</a></span></li><li><span><a href=\"#LogisticRegression\" data-toc-modified-id=\"LogisticRegression-2.1.3\"><span class=\"toc-item-num\">2.1.3&nbsp;&nbsp;</span>LogisticRegression</a></span></li><li><span><a href=\"#CatBoost-Classifier\" data-toc-modified-id=\"CatBoost-Classifier-2.1.4\"><span class=\"toc-item-num\">2.1.4&nbsp;&nbsp;</span>CatBoost Classifier</a></span></li></ul></li><li><span><a href=\"#Обучение-на-признаках-TF-IDF\" data-toc-modified-id=\"Обучение-на-признаках-TF-IDF-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Обучение на признаках <em>TF-IDF</em></a></span><ul class=\"toc-item\"><li><span><a href=\"#LightGBM\" data-toc-modified-id=\"LightGBM-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>LightGBM</a></span></li><li><span><a href=\"#RandomForestClassifier\" data-toc-modified-id=\"RandomForestClassifier-2.2.2\"><span class=\"toc-item-num\">2.2.2&nbsp;&nbsp;</span>RandomForestClassifier</a></span></li><li><span><a href=\"#LogisticRegression\" data-toc-modified-id=\"LogisticRegression-2.2.3\"><span class=\"toc-item-num\">2.2.3&nbsp;&nbsp;</span>LogisticRegression</a></span></li><li><span><a href=\"#CatBoost-Classifier\" data-toc-modified-id=\"CatBoost-Classifier-2.2.4\"><span class=\"toc-item-num\">2.2.4&nbsp;&nbsp;</span>CatBoost Classifier</a></span></li><li><span><a href=\"#BernoulliNB\" data-toc-modified-id=\"BernoulliNB-2.2.5\"><span class=\"toc-item-num\">2.2.5&nbsp;&nbsp;</span>BernoulliNB</a></span></li></ul></li><li><span><a href=\"#Сравнение-моделей\" data-toc-modified-id=\"Сравнение-моделей-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Сравнение моделей</a></span></li></ul></li><li><span><a href=\"#Тестирование\" data-toc-modified-id=\"Тестирование-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Тестирование</a></span></li><li><span><a href=\"#Вывод\" data-toc-modified-id=\"Вывод-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Вывод</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad15382",
   "metadata": {},
   "source": [
    "# Антитоксичная модель"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51d7ab0",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. <br>\n",
    "\n",
    "Необходимо научить модель классифицировать комментарии на позитивные и негативные. В распоряжении имеется набор данных (тексты на английском языке) с разметкой о токсичности правок. <br>\n",
    "\n",
    "Значением метрики качества F1 должно быть не меньше 0.75."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b5658ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow\n",
    "import re\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import transformers\n",
    "from transformers import DistilBertConfig, DistilBertModel, DistilBertTokenizer\n",
    "\n",
    "from tqdm import notebook\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, roc_curve, roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV\n",
    ")\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import make_pipeline\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ce04973",
   "metadata": {},
   "outputs": [],
   "source": [
    "STATE = np.random.RandomState(12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa081476",
   "metadata": {},
   "source": [
    "## Загрузка и подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12545bd",
   "metadata": {},
   "source": [
    "Для начала загрузим и посмотрим на данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52548e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159292, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 159292 entries, 0 to 159450\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159292 non-null  object\n",
      " 1   toxic   159292 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('toxic_comments.csv', index_col=0)\n",
    "print(data.shape)\n",
    "display(data.head())\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a076f577",
   "metadata": {},
   "source": [
    "В нашем распоряжении имеется достаточно большой объем данных (159 тысяч строк и два столбца). Пустых значений нет. <br>\n",
    "В столбце *text* представлены твиты на английском языке, а в *toxic* - является твит \"токсичным\". <br>\n",
    "Далее нам стоит очистить текст для дальнейшей работы с ним."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4a68a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для очистки текста\n",
    "def clear_text(text):\n",
    "    clear_text = re.sub(r'[^a-zA-Z ]', ' ', text).split()\n",
    "    clear_text = ' '.join(clear_text)\n",
    "    return(clear_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59a79bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для приведения слов текста к \"лемме\"\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize(text):\n",
    "    text = text.lower()\n",
    "    text = [wnl.lemmatize(i,j[0].lower()) if j[0].lower() in ['a','n','v'] else wnl.lemmatize(i) for i,j in pos_tag(word_tokenize(text))]\n",
    "    text = ' '.join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe32bb7",
   "metadata": {},
   "source": [
    "Также в дальнейшем мы отберем не слишком длинные твиты, поэтому удет полезно знать количество слов в строках текста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80a5a980",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut(tweet):\n",
    "    return len(tweet.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e851dab7",
   "metadata": {},
   "source": [
    "Очистим текст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4d2218c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(clear_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b646140",
   "metadata": {},
   "source": [
    "Также проверим на дубликаты и, если обнаружим их, удалим."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66f5c4a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1148"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27858001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop_duplicates(inplace=True)\n",
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58717446",
   "metadata": {},
   "source": [
    "Теперь добавим столбец с количеством слов для удобства."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52722be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['n_words'] = data['text'].apply(cut)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a443e8c",
   "metadata": {},
   "source": [
    "Для анализа возьмем твиты длиной не более 60 слов. Это уменьшит вычислительную мощность, необходимую на преобразование в признаки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c26541c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.query('n_words <= 60')\n",
    "data = data.drop('n_words', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5328583c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 107475 entries, 0 to 159450\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    107475 non-null  object\n",
      " 1   toxic   107475 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6097080d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.881182\n",
      "1    0.118818\n",
      "Name: toxic, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_frequency = data['toxic'].value_counts(normalize=True)\n",
    "print(class_frequency)\n",
    "class_frequency.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f654399",
   "metadata": {},
   "source": [
    "Итак, мы имеем несбалансированную классификацию. Мы умеем с ней бороться, чем мы и займемся позже. <br>\n",
    "Сейчас - разделение на тестовую и тренировочную выборки в соотношении 2:8 соответственно."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f296b5",
   "metadata": {},
   "source": [
    "В исходном датафрейме 150 000 строк. Их обработка требует значительных мощностей, поэтому возьмем лишь часть данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be6e955c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.8848\n",
      "1    0.1152\n",
      "Name: toxic, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = data.sample(10000).reset_index(drop=True)\n",
    "class_frequency = data['toxic'].value_counts(normalize=True)\n",
    "print(class_frequency)\n",
    "class_frequency.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a75c8b",
   "metadata": {},
   "source": [
    "Настало время лемматизации!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0aa880e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Yuriy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Yuriy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Yuriy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ebccfc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text_lem'] = data['text'].apply(lemmatize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7630e055",
   "metadata": {},
   "source": [
    "Посмотрим на получившийся фрейм данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3640d92b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>text_lem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You should put the photo of Aristidh Kola for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>you should put the photo of aristidh kola for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am attempting to a dumping ground talk page ...</td>\n",
       "      <td>0</td>\n",
       "      <td>i be attempt to a dumping ground talk page her...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OK I understood now Thank you</td>\n",
       "      <td>0</td>\n",
       "      <td>ok i understand now thank you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I agree I just wanted to do the same revert be...</td>\n",
       "      <td>1</td>\n",
       "      <td>i agree i just want to do the same revert beca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Explain how that argument was fallacious You a...</td>\n",
       "      <td>0</td>\n",
       "      <td>explain how that argument be fallacious you ar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  You should put the photo of Aristidh Kola for ...      0   \n",
       "1  I am attempting to a dumping ground talk page ...      0   \n",
       "2                      OK I understood now Thank you      0   \n",
       "3  I agree I just wanted to do the same revert be...      1   \n",
       "4  Explain how that argument was fallacious You a...      0   \n",
       "\n",
       "                                            text_lem  \n",
       "0  you should put the photo of aristidh kola for ...  \n",
       "1  i be attempt to a dumping ground talk page her...  \n",
       "2                      ok i understand now thank you  \n",
       "3  i agree i just want to do the same revert beca...  \n",
       "4  explain how that argument be fallacious you ar...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac33d151",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.2, random_state=STATE)\n",
    "\n",
    "features_train = train['text_lem'].reset_index(drop=True)\n",
    "features_test = test['text_lem'].reset_index(drop=True)\n",
    "\n",
    "target_train = train['toxic'].reset_index(drop=True)\n",
    "target_test = test['toxic'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c969de5",
   "metadata": {},
   "source": [
    "### Embedding с помощью toxicBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8127bb15",
   "metadata": {},
   "source": [
    "Для получения признаков воспользуемся Бертом, обученном на английском языке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14480cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_embeddings1(features):\n",
    "    tokenizer = transformers.BertTokenizer(vocab_file='toxic_bert/vocab.txt')\n",
    "\n",
    "    tokenized = features.apply(lambda x: tokenizer.encode(x, add_special_tokens=True, max_length=60, truncation=True, padding=True))\n",
    "\n",
    "    max_len = 0\n",
    "    for i in tokenized.values:\n",
    "        if len(i) > max_len:\n",
    "            max_len = len(i)\n",
    "\n",
    "    padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values])\n",
    "\n",
    "    attention_mask = np.where(padded != 0, 1, 0)\n",
    "\n",
    "    config = transformers.BertConfig.from_json_file(\n",
    "        'toxic_bert/config.json')\n",
    "    model = transformers.BertModel.from_pretrained(\n",
    "        'toxic_bert/pytorch_model.bin', config=config)\n",
    "\n",
    "    batch_size = 100\n",
    "    embeddings = []\n",
    "    for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
    "            batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)]) \n",
    "            attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "        \n",
    "            with torch.no_grad():\n",
    "                batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "        \n",
    "            embeddings.append(batch_embeddings[0][:,0,:].numpy())\n",
    "        \n",
    "    features = np.concatenate(embeddings)\n",
    "    features = pd.DataFrame(features)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b043cccf",
   "metadata": {},
   "source": [
    "Осталось только преобразовать признаки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a75ce7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#features_train_bert = make_embeddings1(features_train)\n",
    "#features_train_bert.to_csv('features_train_toxic_bert')\n",
    "#target_train.to_csv('target_train_toxic_bert')\n",
    "\n",
    "#features_test_bert = make_embeddings1(features_test)\n",
    "#features_test_bert.to_csv('features_test_toxic_bert')\n",
    "#target_test.to_csv('target_test_toxic_bert')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85944245",
   "metadata": {},
   "source": [
    "Потребовалось около 13 часов для того, чтобы обработать 10 000 строк. Получившиеся признаки были сохранены в формате csv для быстрого доступа к ним, и теперь в нашем распоряжении имеется множество данных для обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4d0f549",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_bert = pd.read_csv('features_train_toxic_bert', index_col=0)\n",
    "target_train_bert = pd.read_csv('target_train_toxic_bert', index_col=0)\n",
    "target_train_bert = target_train_bert['toxic']\n",
    "\n",
    "features_test_bert = pd.read_csv('features_test_toxic_bert', index_col=0)\n",
    "target_test_bert = pd.read_csv('target_test_toxic_bert', index_col=0)\n",
    "target_test_bert = target_test_bert['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b16d1ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тренировочная выборка: (8000, 768) (8000,)\n",
      "Тестовая выборка выборка: (2000, 768) (2000,)\n"
     ]
    }
   ],
   "source": [
    "print('Тренировочная выборка:', features_train_bert.shape, target_train_bert.shape)\n",
    "print('Тестовая выборка выборка:', features_test_bert.shape, target_test_bert.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2147c2",
   "metadata": {},
   "source": [
    "Итого: у нас 768 признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2af550",
   "metadata": {},
   "source": [
    "### *TF-IDF* признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f1f1da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Yuriy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "corpus_train = features_train\n",
    "corpus_test = features_test\n",
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk_stopwords.words('english'))\n",
    "count_tf_idf = TfidfVectorizer(stop_words=list(stopwords))\n",
    "features_train_tf = count_tf_idf.fit_transform(corpus_train)\n",
    "features_test_tf = count_tf_idf.transform(corpus_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "521713e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_tf = pd.DataFrame(features_train_tf.todense())\n",
    "features_test_tf = pd.DataFrame(features_test_tf.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7bbc30e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тренировочная выборка: (8000, 15210) (8000,)\n",
      "Тестовая выборка выборка: (2000, 15210) (2000,)\n"
     ]
    }
   ],
   "source": [
    "print('Тренировочная выборка:', features_train_tf.shape, target_train.shape)\n",
    "print('Тестовая выборка выборка:', features_test_tf.shape, target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f7a10e",
   "metadata": {},
   "source": [
    "### Борьба с несбалансированностью классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2725ad36",
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = SMOTE(random_state=STATE)\n",
    "features_train_bert_up, target_train_bert_up = oversample.fit_resample(features_train_bert, target_train_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "40fa5e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = SMOTE(random_state=STATE)\n",
    "features_train_tf_up, target_train_tf_up = oversample.fit_resample(features_train_tf, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4f61ad",
   "metadata": {},
   "source": [
    "## Обучение моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a773ad4",
   "metadata": {},
   "source": [
    "### Обучение да признаках BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5332a133",
   "metadata": {},
   "source": [
    "#### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "49fc02d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=5, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5\n",
      "best_score: 0.9174178947575886\n",
      "best_params: {'lgbmclassifier__num_leaves': 500, 'lgbmclassifier__n_estimators': 500, 'lgbmclassifier__min_data_in_leaf': 5, 'lgbmclassifier__max_depth': -1}\n",
      "Wall time: 15min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_lgb = LGBMClassifier(random_state=STATE)\n",
    "\n",
    "pipeline_lgb = make_pipeline(SMOTE(random_state=STATE), \n",
    "                              model_lgb)\n",
    "\n",
    "param_grid_lgb = {\n",
    "    'lgbmclassifier__max_depth': [9, 21, -1],\n",
    "    'lgbmclassifier__min_data_in_leaf': [4, 5],\n",
    "    'lgbmclassifier__num_leaves': [300, 500],\n",
    "    'lgbmclassifier__n_estimators' : [500]\n",
    "}\n",
    "\n",
    "gs_lgb_bert = RandomizedSearchCV(\n",
    "    pipeline_lgb, \n",
    "    param_distributions=param_grid_lgb, \n",
    "    scoring='f1', \n",
    "    n_jobs=-1,\n",
    "    random_state=STATE\n",
    ")\n",
    "\n",
    "gs_lgb_bert.fit(features_train_bert, target_train_bert)\n",
    "\n",
    "lgb_bert_score = gs_lgb_bert.best_score_\n",
    "gs_lgb_bert_best_params = gs_lgb_bert.best_params_\n",
    "\n",
    "# лучшее значение f1 на кросс-валидации\n",
    "print(f'best_score: {lgb_bert_score}')\n",
    "# лучшие гиперпараметры\n",
    "print(f'best_params: {gs_lgb_bert_best_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997a7cce",
   "metadata": {},
   "source": [
    "#### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ae50028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score: 0.9152713186956118\n",
      "best_params: {'randomforestclassifier__n_estimators': 300, 'randomforestclassifier__min_samples_split': 7, 'randomforestclassifier__min_samples_leaf': 2, 'randomforestclassifier__max_depth': 13}\n",
      "Wall time: 7min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_rf = RandomForestClassifier(random_state=STATE)\n",
    "\n",
    "pipeline_rf = make_pipeline(SMOTE(random_state=STATE), \n",
    "                              model_rf)\n",
    "\n",
    "param_grid_rf = {\n",
    "    'randomforestclassifier__n_estimators': [100, 300],\n",
    "    'randomforestclassifier__max_depth': [5, 13, 27],\n",
    "    'randomforestclassifier__min_samples_split': [2, 7, 13],\n",
    "    'randomforestclassifier__min_samples_leaf': [2, 4, 6]\n",
    "}\n",
    "\n",
    "gs_rf_bert = RandomizedSearchCV(\n",
    "    pipeline_rf, \n",
    "    param_distributions=param_grid_rf, \n",
    "    scoring='f1', \n",
    "    n_jobs=-1, \n",
    "    random_state=STATE\n",
    ")\n",
    "\n",
    "gs_rf_bert.fit(features_train_bert, target_train_bert)\n",
    "\n",
    "rf_bert_score = gs_rf_bert.best_score_\n",
    "gs_rf_bert_best_params = gs_rf_bert.best_params_\n",
    "print(f'best_score: {rf_bert_score}')\n",
    "print(f'best_params: {gs_rf_bert_best_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad47c3f",
   "metadata": {},
   "source": [
    "#### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b29f4c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score: 0.8969694527225218\n",
      "best_params: {'logisticregression__C': 0.1, 'logisticregression__max_iter': 100, 'logisticregression__solver': 'lbfgs'}\n",
      "Wall time: 11min 27s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_lr = LogisticRegression(random_state=STATE)\n",
    "\n",
    "pipeline_lr = make_pipeline(SMOTE(random_state=STATE), \n",
    "                              model_lr)\n",
    "\n",
    "param_grid_lr = {\n",
    "    'logisticregression__solver' : ['lbfgs', 'liblinear', 'newton-cg', 'sag', 'saga'],\n",
    "    'logisticregression__max_iter' : [100, 200, 500],\n",
    "    'logisticregression__C' : [0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "gs_lr_bert = GridSearchCV(\n",
    "    pipeline_lr, \n",
    "    param_grid=param_grid_lr, \n",
    "    scoring='f1', \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "gs_lr_bert.fit(features_train_bert, target_train_bert)\n",
    "\n",
    "lr_bert_score = gs_lr_bert.best_score_\n",
    "gs_lr_bert_best_params = gs_lr_bert.best_params_\n",
    "\n",
    "# лучшее значение RMSE на кросс-валидации\n",
    "print(f'best_score: {lr_bert_score}')\n",
    "# лучшие гиперпараметры\n",
    "print(f'best_params: {gs_lr_bert_best_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d07a021",
   "metadata": {},
   "source": [
    "#### CatBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "168ed4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score: 0.9129548861963631\n",
      "best_params: {'catboostclassifier__custom_loss': 'F1', 'catboostclassifier__iterations': 700, 'catboostclassifier__learning_rate': 0.1}\n",
      "Wall time: 12min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_cat = CatBoostClassifier(verbose=False)\n",
    "\n",
    "pipeline_cat = make_pipeline(SMOTE(random_state=STATE), \n",
    "                              model_cat)\n",
    "\n",
    "param_grid_cat = {\n",
    "    'catboostclassifier__learning_rate': [0.04, 0.1],\n",
    "    'catboostclassifier__iterations' : [200, 500, 700],\n",
    "    'catboostclassifier__custom_loss' : ['F1']\n",
    "}\n",
    "\n",
    "gs_cat_bert = GridSearchCV(\n",
    "    pipeline_cat, \n",
    "    param_grid=param_grid_cat, \n",
    "    scoring='f1', \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "gs_cat_bert.fit(features_train_bert, target_train_bert)\n",
    "\n",
    "cat_bert_score = gs_cat_bert.best_score_\n",
    "gs_cat_bert_best_params = gs_cat_bert.best_params_\n",
    "\n",
    "# лучшее значение RMSE на кросс-валидации\n",
    "print(f'best_score: {cat_bert_score}')\n",
    "# лучшие гиперпараметры\n",
    "print(f'best_params: {gs_cat_bert_best_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d418c1c",
   "metadata": {},
   "source": [
    "### Обучение на признаках *TF-IDF*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f9b32e",
   "metadata": {},
   "source": [
    "#### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b332d3e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "5 fits failed out of a total of 45.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\pipeline.py\", line 297, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py\", line 967, in fit\n",
      "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\", line 2605, in __init__\n",
      "    train_set.construct()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\", line 1815, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\", line 1474, in _lazy_init\n",
      "    data, feature_name, categorical_feature, self.pandas_categorical = _data_from_pandas(data,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\", line 568, in _data_from_pandas\n",
      "    data = data.rename(columns=str)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\", line 324, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\", line 5039, in rename\n",
      "    return super().rename(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\", line 1133, in rename\n",
      "    result = self if inplace else self.copy(deep=copy)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\", line 5933, in copy\n",
      "    data = self._mgr.copy(deep=deep)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 603, in copy\n",
      "    res._consolidate_inplace()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 624, in _consolidate_inplace\n",
      "    self.blocks = tuple(_consolidate(self.blocks))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 1974, in _consolidate\n",
      "    merged_blocks = _merge_blocks(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 2001, in _merge_blocks\n",
      "    new_values = np.vstack([b.values for b in blocks])  # type: ignore[misc]\n",
      "  File \"<__array_function__ internals>\", line 5, in vstack\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\shape_base.py\", line 283, in vstack\n",
      "    return _nx.concatenate(arrs, 0)\n",
      "  File \"<__array_function__ internals>\", line 5, in concatenate\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 1.28 GiB for an array with shape (15210, 11330) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\pipeline.py\", line 297, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py\", line 967, in fit\n",
      "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\", line 2605, in __init__\n",
      "    train_set.construct()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\", line 1815, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\", line 1474, in _lazy_init\n",
      "    data, feature_name, categorical_feature, self.pandas_categorical = _data_from_pandas(data,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\", line 568, in _data_from_pandas\n",
      "    data = data.rename(columns=str)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\", line 324, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\", line 5039, in rename\n",
      "    return super().rename(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\", line 1133, in rename\n",
      "    result = self if inplace else self.copy(deep=copy)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\", line 5933, in copy\n",
      "    data = self._mgr.copy(deep=deep)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 603, in copy\n",
      "    res._consolidate_inplace()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 624, in _consolidate_inplace\n",
      "    self.blocks = tuple(_consolidate(self.blocks))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 1974, in _consolidate\n",
      "    merged_blocks = _merge_blocks(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 2001, in _merge_blocks\n",
      "    new_values = np.vstack([b.values for b in blocks])  # type: ignore[misc]\n",
      "  File \"<__array_function__ internals>\", line 5, in vstack\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\shape_base.py\", line 283, in vstack\n",
      "    return _nx.concatenate(arrs, 0)\n",
      "  File \"<__array_function__ internals>\", line 5, in concatenate\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 1.28 GiB for an array with shape (15210, 11332) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\pipeline.py\", line 297, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py\", line 967, in fit\n",
      "    super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py\", line 748, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py\", line 271, in train\n",
      "    booster = Booster(params=params, train_set=train_set)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\", line 2605, in __init__\n",
      "    train_set.construct()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\", line 1815, in construct\n",
      "    self._lazy_init(self.data, label=self.label,\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\", line 1538, in _lazy_init\n",
      "    self.__init_from_np2d(data, params_str, ref_dataset)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\", line 1654, in __init_from_np2d\n",
      "    data = np.array(mat.reshape(mat.size), dtype=mat.dtype, copy=False)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 1.28 GiB for an array with shape (11332, 15210) and data type float64\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.74227121 0.72991773 0.73603825 0.73789614\n",
      " 0.73569952 0.73570086 0.73338633]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score: 0.7422712058914505\n",
      "best_params: {'lgbmclassifier__max_depth': 7, 'lgbmclassifier__min_data_in_leaf': 5, 'lgbmclassifier__n_estimators': 600, 'lgbmclassifier__num_leaves': 500}\n",
      "Wall time: 9min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_lgb = LGBMClassifier(random_state=STATE)\n",
    "\n",
    "pipeline_lgb = make_pipeline(SMOTE(random_state=STATE), \n",
    "                              model_lgb)\n",
    "\n",
    "param_grid_lgb = {\n",
    "    'lgbmclassifier__max_depth': [7, 13, 30],\n",
    "    'lgbmclassifier__min_data_in_leaf': [5],\n",
    "    'lgbmclassifier__num_leaves': [500],\n",
    "    'lgbmclassifier__n_estimators' : [400, 500, 600]\n",
    "}\n",
    "\n",
    "\n",
    "gs_lgb = GridSearchCV(\n",
    "    pipeline_lgb,\n",
    "    param_grid=param_grid_lgb, \n",
    "    scoring='f1', \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "gs_lgb.fit(features_train_tf, target_train)\n",
    "\n",
    "lgb_tf_score = gs_lgb.best_score_\n",
    "gs_lgb_tf_best_params = gs_lgb.best_params_\n",
    "\n",
    "# лучшее значение f1 на кросс-валидации\n",
    "print(f'best_score: {lgb_tf_score}')\n",
    "# лучшие гиперпараметры\n",
    "print(f'best_params: {gs_lgb_tf_best_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e50ef20",
   "metadata": {},
   "source": [
    "#### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6c2b93b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "3 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\pipeline.py\", line 293, in fit\n",
      "    Xt, yt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\pipeline.py\", line 250, in _fit\n",
      "    X, y, fitted_transformer = fit_resample_one_cached(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\pipeline.py\", line 422, in _fit_resample_one\n",
      "    X_res, y_res = sampler.fit_resample(X, y, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\base.py\", line 203, in fit_resample\n",
      "    return super().fit_resample(X, y)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\base.py\", line 88, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\over_sampling\\_smote\\base.py\", line 356, in _fit_resample\n",
      "    X_new, y_new = self._make_samples(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\over_sampling\\_smote\\base.py\", line 110, in _make_samples\n",
      "    X_new = self._generate_samples(X, nn_data, nn_num, rows, cols, steps)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\over_sampling\\_smote\\base.py\", line 154, in _generate_samples\n",
      "    diffs = nn_data[nn_num[rows, cols]] - X[rows]\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 572. MiB for an array with shape (4930, 15210) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\pipeline.py\", line 293, in fit\n",
      "    Xt, yt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\pipeline.py\", line 250, in _fit\n",
      "    X, y, fitted_transformer = fit_resample_one_cached(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\pipeline.py\", line 422, in _fit_resample_one\n",
      "    X_res, y_res = sampler.fit_resample(X, y, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\base.py\", line 203, in fit_resample\n",
      "    return super().fit_resample(X, y)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\base.py\", line 88, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\over_sampling\\_smote\\base.py\", line 356, in _fit_resample\n",
      "    X_new, y_new = self._make_samples(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\over_sampling\\_smote\\base.py\", line 110, in _make_samples\n",
      "    X_new = self._generate_samples(X, nn_data, nn_num, rows, cols, steps)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\over_sampling\\_smote\\base.py\", line 161, in _generate_samples\n",
      "    X_new = X[rows] + steps * diffs\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 572. MiB for an array with shape (4932, 15210) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\pipeline.py\", line 293, in fit\n",
      "    Xt, yt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\pipeline.py\", line 250, in _fit\n",
      "    X, y, fitted_transformer = fit_resample_one_cached(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\pipeline.py\", line 422, in _fit_resample_one\n",
      "    X_res, y_res = sampler.fit_resample(X, y, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\base.py\", line 203, in fit_resample\n",
      "    return super().fit_resample(X, y)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\base.py\", line 88, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\over_sampling\\_smote\\base.py\", line 356, in _fit_resample\n",
      "    X_new, y_new = self._make_samples(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\over_sampling\\_smote\\base.py\", line 110, in _make_samples\n",
      "    X_new = self._generate_samples(X, nn_data, nn_num, rows, cols, steps)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\over_sampling\\_smote\\base.py\", line 161, in _generate_samples\n",
      "    X_new = X[rows] + steps * diffs\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 572. MiB for an array with shape (4930, 15210) and data type float64\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.63178399        nan 0.63123    0.63932337 0.65136788\n",
      " 0.63178399 0.65900142 0.65264297 0.67008908]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score: 0.6700890823583701\n",
      "best_params: {'randomforestclassifier__n_estimators': 300, 'randomforestclassifier__min_samples_split': 10, 'randomforestclassifier__min_samples_leaf': 3, 'randomforestclassifier__max_depth': 27}\n",
      "Wall time: 4min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_rf = RandomForestClassifier(random_state=STATE)\n",
    "\n",
    "pipeline_rf = make_pipeline(SMOTE(random_state=STATE), \n",
    "                              model_rf)\n",
    "\n",
    "param_grid_rf = {\n",
    "    'randomforestclassifier__n_estimators': [100, 300],\n",
    "    'randomforestclassifier__max_depth': [5, 13, 27],\n",
    "    'randomforestclassifier__min_samples_split': [5, 7, 10],\n",
    "    'randomforestclassifier__min_samples_leaf': [3, 4]\n",
    "}\n",
    "\n",
    "gs_rf = RandomizedSearchCV(\n",
    "    pipeline_rf, \n",
    "    param_distributions=param_grid_rf, \n",
    "    scoring='f1', \n",
    "    n_jobs=-1, \n",
    "    random_state=STATE\n",
    ")\n",
    "\n",
    "gs_rf.fit(features_train_tf, target_train)\n",
    "\n",
    "rf_tf_score = gs_rf.best_score_\n",
    "gs_rf_tf_best_params = gs_rf.best_params_\n",
    "print(f'best_score: {rf_tf_score}')\n",
    "print(f'best_params: {gs_rf_tf_best_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fc16a8",
   "metadata": {},
   "source": [
    "#### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bd1c1467",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "4 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\pipeline.py\", line 293, in fit\n",
      "    Xt, yt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\pipeline.py\", line 250, in _fit\n",
      "    X, y, fitted_transformer = fit_resample_one_cached(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\pipeline.py\", line 422, in _fit_resample_one\n",
      "    X_res, y_res = sampler.fit_resample(X, y, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\base.py\", line 203, in fit_resample\n",
      "    return super().fit_resample(X, y)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\base.py\", line 88, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\over_sampling\\_smote\\base.py\", line 356, in _fit_resample\n",
      "    X_new, y_new = self._make_samples(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\over_sampling\\_smote\\base.py\", line 110, in _make_samples\n",
      "    X_new = self._generate_samples(X, nn_data, nn_num, rows, cols, steps)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\over_sampling\\_smote\\base.py\", line 161, in _generate_samples\n",
      "    X_new = X[rows] + steps * diffs\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 572. MiB for an array with shape (4930, 15210) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\pipeline.py\", line 293, in fit\n",
      "    Xt, yt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\pipeline.py\", line 250, in _fit\n",
      "    X, y, fitted_transformer = fit_resample_one_cached(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\pipeline.py\", line 422, in _fit_resample_one\n",
      "    X_res, y_res = sampler.fit_resample(X, y, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\base.py\", line 203, in fit_resample\n",
      "    return super().fit_resample(X, y)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\base.py\", line 88, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\over_sampling\\_smote\\base.py\", line 356, in _fit_resample\n",
      "    X_new, y_new = self._make_samples(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\over_sampling\\_smote\\base.py\", line 110, in _make_samples\n",
      "    X_new = self._generate_samples(X, nn_data, nn_num, rows, cols, steps)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\over_sampling\\_smote\\base.py\", line 161, in _generate_samples\n",
      "    X_new = X[rows] + steps * diffs\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 572. MiB for an array with shape (4932, 15210) and data type float64\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.69270091 0.69270091 0.72096783\n",
      " 0.63098751 0.72096783 0.66468745 0.72096783]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score: 0.7209678347184215\n",
      "best_params: {'logisticregression__solver': 'liblinear', 'logisticregression__max_iter': 500, 'logisticregression__C': 1}\n",
      "Wall time: 12min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_lr = LogisticRegression(random_state=STATE)\n",
    "\n",
    "pipeline_lr = make_pipeline(SMOTE(random_state=STATE), \n",
    "                              model_lr)\n",
    "\n",
    "param_grid_lr = {\n",
    "    'logisticregression__solver' : ['lbfgs', 'liblinear', 'newton-cg', 'sag', 'saga'],\n",
    "    'logisticregression__max_iter' : [100, 200, 500],\n",
    "    'logisticregression__C' : [0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "gs_lr = RandomizedSearchCV(\n",
    "    pipeline_lr, \n",
    "    param_distributions=param_grid_lr, \n",
    "    scoring='f1', \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "gs_lr.fit(features_train_tf, target_train)\n",
    "\n",
    "lr_tf_score = gs_lr.best_score_\n",
    "gs_lr_tf_best_params = gs_lr.best_params_\n",
    "\n",
    "# лучшее значение RMSE на кросс-валидации\n",
    "print(f'best_score: {lr_tf_score}')\n",
    "# лучшие гиперпараметры\n",
    "print(f'best_params: {gs_lr_tf_best_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e721582d",
   "metadata": {},
   "source": [
    "#### CatBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "327da530",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "4 fits failed out of a total of 20.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\pipeline.py\", line 293, in fit\n",
      "    Xt, yt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\pipeline.py\", line 250, in _fit\n",
      "    X, y, fitted_transformer = fit_resample_one_cached(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\pipeline.py\", line 422, in _fit_resample_one\n",
      "    X_res, y_res = sampler.fit_resample(X, y, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\base.py\", line 203, in fit_resample\n",
      "    return super().fit_resample(X, y)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\base.py\", line 88, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\over_sampling\\_smote\\base.py\", line 356, in _fit_resample\n",
      "    X_new, y_new = self._make_samples(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\over_sampling\\_smote\\base.py\", line 110, in _make_samples\n",
      "    X_new = self._generate_samples(X, nn_data, nn_num, rows, cols, steps)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\over_sampling\\_smote\\base.py\", line 161, in _generate_samples\n",
      "    X_new = X[rows] + steps * diffs\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 572. MiB for an array with shape (4930, 15210) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\pipeline.py\", line 293, in fit\n",
      "    Xt, yt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\pipeline.py\", line 250, in _fit\n",
      "    X, y, fitted_transformer = fit_resample_one_cached(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\pipeline.py\", line 422, in _fit_resample_one\n",
      "    X_res, y_res = sampler.fit_resample(X, y, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\base.py\", line 203, in fit_resample\n",
      "    return super().fit_resample(X, y)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\base.py\", line 88, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\over_sampling\\_smote\\base.py\", line 356, in _fit_resample\n",
      "    X_new, y_new = self._make_samples(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\over_sampling\\_smote\\base.py\", line 110, in _make_samples\n",
      "    X_new = self._generate_samples(X, nn_data, nn_num, rows, cols, steps)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\over_sampling\\_smote\\base.py\", line 161, in _generate_samples\n",
      "    X_new = X[rows] + steps * diffs\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 572. MiB for an array with shape (4932, 15210) and data type float64\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [      nan       nan       nan 0.7306366]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score: 0.7306365950030747\n",
      "best_params: {'catboostclassifier__custom_loss': 'F1', 'catboostclassifier__iterations': 700, 'catboostclassifier__learning_rate': 0.03}\n",
      "Wall time: 7min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_cat = CatBoostClassifier(verbose=False)\n",
    "\n",
    "pipeline_cat = make_pipeline(SMOTE(random_state=STATE), \n",
    "                              model_cat)\n",
    "\n",
    "param_grid_cat = {\n",
    "    'catboostclassifier__learning_rate': [0.03],\n",
    "    'catboostclassifier__iterations' : [100, 300, 500, 700],\n",
    "    'catboostclassifier__custom_loss' : ['F1']\n",
    "}\n",
    "\n",
    "gs_cat = GridSearchCV(\n",
    "    pipeline_cat, \n",
    "    param_grid=param_grid_cat, \n",
    "    scoring='f1', \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "gs_cat.fit(features_train_tf, target_train)\n",
    "\n",
    "cat_tf_score = gs_cat.best_score_\n",
    "gs_cat_tf_best_params = gs_cat.best_params_\n",
    "\n",
    "# лучшее значение RMSE на кросс-валидации\n",
    "print(f'best_score: {cat_tf_score}')\n",
    "# лучшие гиперпараметры\n",
    "print(f'best_params: {gs_cat_tf_best_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342ae2bd",
   "metadata": {},
   "source": [
    "#### BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5e9dff7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "1 fits failed out of a total of 55.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\pipeline.py\", line 293, in fit\n",
      "    Xt, yt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\pipeline.py\", line 250, in _fit\n",
      "    X, y, fitted_transformer = fit_resample_one_cached(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\pipeline.py\", line 422, in _fit_resample_one\n",
      "    X_res, y_res = sampler.fit_resample(X, y, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\base.py\", line 203, in fit_resample\n",
      "    return super().fit_resample(X, y)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\base.py\", line 88, in fit_resample\n",
      "    output = self._fit_resample(X, y)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\over_sampling\\_smote\\base.py\", line 356, in _fit_resample\n",
      "    X_new, y_new = self._make_samples(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\over_sampling\\_smote\\base.py\", line 110, in _make_samples\n",
      "    X_new = self._generate_samples(X, nn_data, nn_num, rows, cols, steps)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\over_sampling\\_smote\\base.py\", line 154, in _generate_samples\n",
      "    diffs = nn_data[nn_num[rows, cols]] - X[rows]\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 572. MiB for an array with shape (4930, 15210) and data type float64\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.71217778        nan 0.71113066 0.71077863 0.7121753  0.71255092\n",
      " 0.71295815 0.71295815 0.71371754 0.71334365 0.71334365]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score: 0.7137175409677201\n",
      "best_params: {'bernoullinb__alpha': 0.9800000000000001}\n",
      "Wall time: 5min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_nb = BernoulliNB()\n",
    "\n",
    "pipeline_nb = make_pipeline(SMOTE(random_state=STATE), \n",
    "                              model_nb)\n",
    "\n",
    "param_grid_nb = {\n",
    "    'bernoullinb__alpha': np.arange(0.9, 1.01, 0.01),\n",
    "#    'bernoullinb__fit_prior' : [True, False],\n",
    "#    'bernoullinb__force_alpha' : [True, False]\n",
    "}\n",
    "\n",
    "gs_nb = GridSearchCV(\n",
    "    pipeline_nb, \n",
    "    param_grid=param_grid_nb, \n",
    "    scoring='f1', \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "gs_nb.fit(features_train_tf, target_train)\n",
    "\n",
    "nb_tf_score = gs_nb.best_score_\n",
    "gs_nb_tf_best_params = gs_nb.best_params_\n",
    "\n",
    "# лучшее значение RMSE на кросс-валидации\n",
    "print(f'best_score: {nb_tf_score}')\n",
    "# лучшие гиперпараметры\n",
    "print(f'best_params: {gs_nb_tf_best_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ba363c",
   "metadata": {},
   "source": [
    "### Сравнение моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b324d4eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_7e885_row0_col0, #T_7e885_row0_col1 {\n",
       "  background-color: yellowgreen;\n",
       "}\n",
       "#T_7e885_row2_col1, #T_7e885_row4_col0 {\n",
       "  background-color: coral;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_7e885_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >f1 с признаками BERT</th>\n",
       "      <th class=\"col_heading level0 col1\" >f1 с признаками TF-IDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_7e885_level0_row0\" class=\"row_heading level0 row0\" >LightGBM</th>\n",
       "      <td id=\"T_7e885_row0_col0\" class=\"data row0 col0\" >0.917418</td>\n",
       "      <td id=\"T_7e885_row0_col1\" class=\"data row0 col1\" >0.742271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7e885_level0_row1\" class=\"row_heading level0 row1\" >CatBoostClassifier</th>\n",
       "      <td id=\"T_7e885_row1_col0\" class=\"data row1 col0\" >0.912955</td>\n",
       "      <td id=\"T_7e885_row1_col1\" class=\"data row1 col1\" >0.730637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7e885_level0_row2\" class=\"row_heading level0 row2\" >RandomForestRegressor</th>\n",
       "      <td id=\"T_7e885_row2_col0\" class=\"data row2 col0\" >0.915271</td>\n",
       "      <td id=\"T_7e885_row2_col1\" class=\"data row2 col1\" >0.670089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7e885_level0_row3\" class=\"row_heading level0 row3\" >LogisticRegression</th>\n",
       "      <td id=\"T_7e885_row3_col0\" class=\"data row3 col0\" >0.896969</td>\n",
       "      <td id=\"T_7e885_row3_col1\" class=\"data row3 col1\" >0.720968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_7e885_level0_row4\" class=\"row_heading level0 row4\" >NaiveBayes</th>\n",
       "      <td id=\"T_7e885_row4_col0\" class=\"data row4 col0\" >0.000000</td>\n",
       "      <td id=\"T_7e885_row4_col1\" class=\"data row4 col1\" >0.713718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x13c7e2292e0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column=['f1 с признаками BERT', 'f1 с признаками TF-IDF']\n",
    "\n",
    "comparison_tabl = pd.DataFrame(index=column, columns=['LightGBM', 'CatBoostClassifier', 'RandomForestRegressor','LogisticRegression', 'NaiveBayes'])\n",
    "comparison_tabl['LightGBM'] = lgb_bert_score, lgb_tf_score\n",
    "comparison_tabl['CatBoostClassifier'] = cat_bert_score, cat_tf_score\n",
    "comparison_tabl['RandomForestRegressor'] = rf_bert_score, rf_tf_score\n",
    "comparison_tabl['LogisticRegression'] = lr_bert_score, lr_tf_score\n",
    "comparison_tabl['NaiveBayes'] = 0, nb_tf_score\n",
    "\n",
    "comparison_tabl.T.style.highlight_max(color='yellowgreen',subset=column).highlight_null(null_color='lightgrey').highlight_min(color='coral',subset=column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca0848a",
   "metadata": {},
   "source": [
    "Мы видим, что использование модели, специально обученной на классификацию токсичности текста, заметно повышает качество."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdc54df",
   "metadata": {},
   "source": [
    "## Тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "71095ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 на тестовой выборке: 0.91015625\n"
     ]
    }
   ],
   "source": [
    "best_model = gs_lgb_bert.best_estimator_\n",
    "pred_test = best_model.predict(features_test_bert)\n",
    "f1_test_score = f1_score(target_test_bert, pred_test)\n",
    "print('f1 на тестовой выборке:', f1_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aa00d522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2238010657193606\n"
     ]
    }
   ],
   "source": [
    "dummy = DummyClassifier(strategy='constant', constant=1)\n",
    "dummy.fit(features_train_bert, target_train_bert)\n",
    "predictions = dummy.predict(features_test_bert)\n",
    "result = f1_score(target_test_bert, predictions)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f51c9e86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "probabilities_test = best_model.predict_proba(features_test_bert)\n",
    "probabilities_one_test = probabilities_test[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(target_test_bert, probabilities_one_test)\n",
    "plt.figure()\n",
    "plt.figure(figsize=[7,5])\n",
    "plt.step(fpr,tpr,where='post', label='ROC curve')\n",
    "plt.plot([0,1], [0,1], linestyle='--', label='random')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC-кривая')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "99cd4d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Площадь под roc-кривой для модели LightGBM: 0.994508463186953\n"
     ]
    }
   ],
   "source": [
    "roc_auc = roc_auc_score(target_test_bert, probabilities_one_test)\n",
    "print('Площадь под roc-кривой для модели LightGBM:', roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b315c8cb",
   "metadata": {},
   "source": [
    "В хорошей модели порог отсечения ставит истинно положительные доли как можно ближе к 1, при этом сохраняя ложно положительные доли на самом нижнем из возможных уровней. Вывод: модель отлично справляется со своей задачей."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a147b9b4",
   "metadata": {},
   "source": [
    "## Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbe4a2d",
   "metadata": {},
   "source": [
    "Цель была достигнута - метрика f1 для модели оценки тональности твитов более 0.90. <br>\n",
    "В ходе работы над проектом была проведена очистка и лемматизация текста. Из большого набора данных выбраны 10 000 строк для обучения и тестирования модели. <br>\n",
    "Были рассмотрены два способа создания признаков: TF-IDF и токенизация с помощью toxicBERT. <br>\n",
    "Также в ходе обучения использовались разные модели, среди которых *LightGBM*, логистическая регрессия и наивный баессовский классификатор. Лучший результат показала *LightGBM* - f1 = 0.91 на тестовой выборке."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 2253,
    "start_time": "2023-04-27T12:11:05.440Z"
   },
   {
    "duration": 6569,
    "start_time": "2023-04-27T12:11:07.695Z"
   },
   {
    "duration": 0,
    "start_time": "2023-04-27T12:11:14.266Z"
   },
   {
    "duration": 0,
    "start_time": "2023-04-27T12:11:14.268Z"
   },
   {
    "duration": 0,
    "start_time": "2023-04-27T12:11:14.270Z"
   },
   {
    "duration": 0,
    "start_time": "2023-04-27T12:11:14.271Z"
   },
   {
    "duration": 0,
    "start_time": "2023-04-27T12:11:14.272Z"
   },
   {
    "duration": 0,
    "start_time": "2023-04-27T12:11:14.273Z"
   },
   {
    "duration": 0,
    "start_time": "2023-04-27T12:11:14.274Z"
   },
   {
    "duration": 0,
    "start_time": "2023-04-27T12:11:14.293Z"
   },
   {
    "duration": 0,
    "start_time": "2023-04-27T12:11:14.295Z"
   },
   {
    "duration": 0,
    "start_time": "2023-04-27T12:11:14.296Z"
   },
   {
    "duration": 0,
    "start_time": "2023-04-27T12:11:14.297Z"
   },
   {
    "duration": 287,
    "start_time": "2023-04-27T12:13:03.433Z"
   },
   {
    "duration": 44,
    "start_time": "2023-04-27T12:13:09.257Z"
   },
   {
    "duration": 3,
    "start_time": "2023-04-27T12:13:09.602Z"
   },
   {
    "duration": 4,
    "start_time": "2023-04-27T12:13:12.908Z"
   },
   {
    "duration": 4,
    "start_time": "2023-04-27T12:13:13.417Z"
   },
   {
    "duration": 2,
    "start_time": "2023-04-27T12:13:14.397Z"
   },
   {
    "duration": 18,
    "start_time": "2023-04-27T12:13:15.292Z"
   },
   {
    "duration": 17,
    "start_time": "2023-04-27T12:13:15.690Z"
   },
   {
    "duration": 77,
    "start_time": "2023-04-27T12:13:20.995Z"
   },
   {
    "duration": 50,
    "start_time": "2023-04-27T12:13:41.660Z"
   },
   {
    "duration": 0,
    "start_time": "2023-04-27T12:13:41.713Z"
   },
   {
    "duration": 0,
    "start_time": "2023-04-27T12:13:41.714Z"
   },
   {
    "duration": 0,
    "start_time": "2023-04-27T12:13:41.715Z"
   },
   {
    "duration": 0,
    "start_time": "2023-04-27T12:13:41.716Z"
   },
   {
    "duration": 0,
    "start_time": "2023-04-27T12:13:41.717Z"
   },
   {
    "duration": 6279,
    "start_time": "2023-04-27T12:14:02.489Z"
   },
   {
    "duration": 4,
    "start_time": "2023-04-27T12:14:08.770Z"
   },
   {
    "duration": 362,
    "start_time": "2023-04-27T12:14:08.969Z"
   },
   {
    "duration": 3283,
    "start_time": "2023-04-27T12:14:21.049Z"
   },
   {
    "duration": 3,
    "start_time": "2023-04-27T12:17:34.375Z"
   },
   {
    "duration": 4,
    "start_time": "2023-04-27T12:17:36.535Z"
   },
   {
    "duration": 3,
    "start_time": "2023-04-27T12:17:40.534Z"
   },
   {
    "duration": 2016,
    "start_time": "2023-04-27T12:17:43.271Z"
   },
   {
    "duration": 187,
    "start_time": "2023-04-27T12:17:46.663Z"
   },
   {
    "duration": 390,
    "start_time": "2023-04-27T12:17:46.951Z"
   },
   {
    "duration": 587,
    "start_time": "2023-04-27T12:17:48.207Z"
   },
   {
    "duration": 30,
    "start_time": "2023-04-27T12:17:48.796Z"
   },
   {
    "duration": 12,
    "start_time": "2023-04-27T12:17:49.439Z"
   },
   {
    "duration": 917,
    "start_time": "2023-04-27T12:17:53.799Z"
   },
   {
    "duration": 6102,
    "start_time": "2023-04-27T12:17:56.535Z"
   },
   {
    "duration": 12,
    "start_time": "2023-04-27T12:18:02.639Z"
   },
   {
    "duration": 270,
    "start_time": "2023-04-27T12:18:02.653Z"
   },
   {
    "duration": 8,
    "start_time": "2023-04-27T12:18:06.639Z"
   },
   {
    "duration": 5,
    "start_time": "2023-04-27T12:18:50.423Z"
   },
   {
    "duration": 6,
    "start_time": "2023-04-27T12:18:56.838Z"
   },
   {
    "duration": 5,
    "start_time": "2023-04-27T12:19:05.911Z"
   },
   {
    "duration": 107,
    "start_time": "2023-04-27T12:23:40.034Z"
   },
   {
    "duration": 116,
    "start_time": "2023-04-27T12:33:04.707Z"
   },
   {
    "duration": 97,
    "start_time": "2023-04-27T12:38:47.109Z"
   },
   {
    "duration": 7345,
    "start_time": "2023-05-02T12:45:51.234Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-02T12:45:58.582Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
